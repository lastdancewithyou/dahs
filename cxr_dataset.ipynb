{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "import gc\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "pd.set_option('mode.chained_assignment',  None) # 경고 제어"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MIMICCXR(Dataset):\n",
    "    def __init__(self, df, args, transform=None, split='train'):\n",
    "        self.data_dir = df['image_path'].values  # 이미지 경로가 포함된 리스트\n",
    "        self.transform = transform\n",
    "        self.args=args\n",
    "        self.CLASSES = ['Atelectasis', 'Cardiomegaly', 'Consolidation', 'Edema',\n",
    "                        'Enlarged Cardiomediastinum', 'Fracture', 'Lung Lesion',\n",
    "                        'Lung Opacity', 'No Finding', 'Pleural Effusion', \n",
    "                        'Pleural Other', 'Pneumonia', 'Pneumothorax', 'Support Devices']\n",
    "        \n",
    "        self.filenames_loaded  = df['dicom_id'].astype(str).values\n",
    "        self.filenames_to_path = dict(zip(df['dicom_id'].astype(str), df['image_path'].values)) # image path\n",
    "\n",
    "        # label\n",
    "        labels = pd.read_csv(\"C:/Users/gangmin/dahs/data/physionet.org/files/mimic-cxr-jpg/2.1.0/mimic-cxr-2.0.0-negbio.csv\")\n",
    "        labels[self.CLASSES] = labels[self.CLASSES].fillna(0) # NaN을 0으로 변환함\n",
    "        labels = labels.replace(-1.0,0.0) # -1인 값이 일부 존재함\n",
    "\n",
    "        metadata_with_labels = filtered_metadata.merge(labels[self.CLASSES+['study_id'] ], how='inner', on='study_id')\n",
    "        self.filenames_to_labels = dict(zip(metadata_with_labels['dicom_id'].values, metadata_with_labels[self.CLASSES].values))\n",
    "\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        filename = self.filenames_loaded[index]\n",
    "        \n",
    "        # 이미지를 로드\n",
    "        try: \n",
    "            img = Image.open(self.filenames_to_path[filename]).convert('RGB')\n",
    "        except Exception as e: \n",
    "            print(f\"Error loading image {filename}: {e}\")\n",
    "            return None, None\n",
    "        \n",
    "        # 라벨을 로드\n",
    "        labels = torch.tensor(self.filenames_to_labels[filename]).float()\n",
    "\n",
    "        # transform이 정의된 경우 적용함\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "        \n",
    "        return img, labels\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.filenames_loaded)\n",
    "    \n",
    "\n",
    "    def get_transforms(args): \n",
    "        normalize = transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "        processed_images_train = [\n",
    "            transforms.Resize(256),\n",
    "            transforms.CenterCrop(224),\n",
    "            transforms.ToTensor(),\n",
    "            normalize\n",
    "        ]\n",
    "\n",
    "        processed_images_test = [\n",
    "            transforms.Resize(args.resize), # 별도의 전처리 위해 args 적용\n",
    "            transforms.CenterCrop(args.crop),\n",
    "            transforms.ToTensor(),\n",
    "            normalize\n",
    "        ]\n",
    "        return processed_images_train, processed_images_test\n",
    "    \n",
    "\n",
    "    def get_cxr_datasets(args): \n",
    "        global filtered_metadata\n",
    "        train_images, test_images = MIMICCXR.get_transforms(args)\n",
    "\n",
    "        metadata = pd.read_csv(\"C:/Users/gangmin/dahs/data/physionet.org/files/mimic-cxr-jpg/2.1.0/mimic-cxr-2.0.0-metadata.csv\")\n",
    "        ap_pa_metadata = metadata[(metadata['ViewPosition']==\"AP\") | (metadata['ViewPosition']==\"PA\")]\n",
    "        filtered_metadata = ap_pa_metadata.iloc[:1000,:]\n",
    "        base_path = \"C:/Users/gangmin/dahs/data/physionet.org/files/mimic-cxr-jpg/2.1.0/files\"\n",
    "\n",
    "        df, image_count = MIMICCXR.find_images(base_path, filtered_metadata)\n",
    "        print(f'{image_count} images in my computer')\n",
    "\n",
    "        train_df, test_df = train_test_split(df, test_size=0.3, random_state=0)\n",
    "\n",
    "        train_dataset = MIMICCXR(train_df, transform=transforms.Compose(train_images), split='train', args=args)\n",
    "        test_dataset = MIMICCXR(test_df, transform=transforms.Compose(test_images), split='test', args=args)\n",
    "\n",
    "        print('CXR dataset preprocessing completed')\n",
    "        return train_dataset, test_dataset\n",
    "\n",
    "\n",
    "    def find_images(base_path, df):\n",
    "        image_count = 0\n",
    "        image_paths = []\n",
    "\n",
    "        for _, row in tqdm(df.iterrows(), total=len(df), desc=\"Finding images\"):\n",
    "            for p_folder in range(10, 20):\n",
    "                p_folder_path = os.path.join(base_path, f'p{p_folder}')\n",
    "                if not os.path.exists(p_folder_path):\n",
    "                    continue\n",
    "                \n",
    "                subject_folder_path = os.path.join(p_folder_path, f'p{row[\"subject_id\"]}')\n",
    "                if not os.path.exists(subject_folder_path):\n",
    "                    continue\n",
    "\n",
    "                study_folder_path = os.path.join(subject_folder_path, f's{row[\"study_id\"]}')\n",
    "                if not os.path.exists(study_folder_path):\n",
    "                    continue\n",
    "\n",
    "                dicom_file_path = os.path.join(study_folder_path, f\"{row['dicom_id']}.jpg\")\n",
    "                if os.path.exists(dicom_file_path):\n",
    "                    image_count += 1\n",
    "                    image_paths.append(dicom_file_path)\n",
    "                    break  # 이미지가 발견되면 다음 row로 이동\n",
    "            else:\n",
    "                image_paths.append(None)  # 이미지를 찾지 못한 경우 None을 추가\n",
    "\n",
    "        df['image_path'] = image_paths\n",
    "        return df, image_count\n",
    "\n",
    "    # def load_images(image_paths):\n",
    "    #     images = []\n",
    "    #     for path in tqdm(image_paths, desc='Images loading...'):\n",
    "    #         if os.path.exists(path):\n",
    "    #             img = cv2.imread(path, cv2.IMREAD_ANYCOLOR)\n",
    "    #             if img is not None: \n",
    "    #                 images.append((path, img))\n",
    "    #             else: \n",
    "    #                 print(f\"Failed to load images: {path}\")\n",
    "    #     return images\n",
    "\n",
    "    # df, image_count = find_images(base_path, filtered_metadata)\n",
    "    # print(f'{image_count} images in my computer')\n",
    "\n",
    "    # images = load_images(df['image_path'].dropna())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Finding images: 100%|██████████| 1000/1000 [00:00<00:00, 5750.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "998 images in my computer\n",
      "CXR dataset preprocessing completed\n"
     ]
    }
   ],
   "source": [
    "class Args: \n",
    "    resize = 256\n",
    "    crop = 224\n",
    "\n",
    "args = Args()\n",
    "train_dataset, test_dataset = MIMICCXR.get_cxr_datasets(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. PyTorch의 이미지 데이터 형식\n",
    "- PyTorch에서 이미지는 [C, H, W] 형식으로 저장됩니다.\n",
    "    -  C: 채널(Channel) 수 (예: RGB 이미지의 경우 3)\n",
    "    - H: 이미지의 높이(Height)\n",
    "    - W: 이미지의 너비(Width)\n",
    "    \n",
    "이 형식은 딥러닝 모델에서 효율적으로 처리할 수 있도록 설계되었습니다. 특히 CNN(Convolutional Neural Networks) 모델에서 이 형식이 주로 사용됩니다.\n",
    "\n",
    "2. Matplotlib의 이미지 데이터 형식:\n",
    "- 일반적으로 이미지 시각화 라이브러리(예: Matplotlib)에서는 이미지를 [H, W, C] 형식으로 처리합니다.\n",
    "H: 이미지의 높이(Height)\n",
    "W: 이미지의 너비(Width)\n",
    "C: 채널(Channel) 수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img, label = train_dataset[0]\n",
    "print(\"Image shape:\", img.shape)\n",
    "print(\"Label:\", label)\n",
    "\n",
    "plt.imshow(img.permute(1, 2, 0))\n",
    "plt.title(\"Label: \" + str(label))\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train dataset 개수: 700\n",
      "test dataset 개수: 300\n"
     ]
    }
   ],
   "source": [
    "print(\"train dataset 개수:\", len(train_dataset))\n",
    "print(\"test dataset 개수:\", len(test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 0: Image shape: torch.Size([3, 224, 224]), Label: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.])\n",
      "Sample 1: Image shape: torch.Size([3, 224, 224]), Label: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1.])\n",
      "Sample 2: Image shape: torch.Size([3, 224, 224]), Label: tensor([1., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.])\n",
      "Sample 3: Image shape: torch.Size([3, 224, 224]), Label: tensor([0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1.])\n",
      "Sample 4: Image shape: torch.Size([3, 224, 224]), Label: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1.])\n",
      "Sample 5: Image shape: torch.Size([3, 224, 224]), Label: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.])\n",
      "Sample 6: Image shape: torch.Size([3, 224, 224]), Label: tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 1., 0.])\n",
      "Sample 7: Image shape: torch.Size([3, 224, 224]), Label: tensor([0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1.])\n",
      "Sample 8: Image shape: torch.Size([3, 224, 224]), Label: tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "Sample 9: Image shape: torch.Size([3, 224, 224]), Label: tensor([0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.])\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(train_dataset)):\n",
    "    img, label = train_dataset[i]\n",
    "    print(f\"Sample {i}: Image shape: {img.shape}, Label: {label}\")\n",
    "    if i == 9:\n",
    "        break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyhealth",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
